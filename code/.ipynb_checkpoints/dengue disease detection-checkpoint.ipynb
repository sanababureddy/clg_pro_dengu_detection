{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dengue Disease Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:/Users/sanab/Documents/clg_pro_dengu_detection/code/dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## top 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns={'id'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get={'yes':1,'medium':1,'no':0,'high':2,'low':0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.vomiting=data.vomiting.map(get)\n",
    "data.nausea=data.nausea.map(get)\n",
    "data.vomiting_blood=data.vomiting_blood.map(get)\n",
    "data.body_pains=data.body_pains.map(get)\n",
    "data.pain_behind_eyes=data.pain_behind_eyes.map(get)\n",
    "data.joint_pains=data.joint_pains.map(get)\n",
    "data.chill=data.chill.map(get)\n",
    "data.headache=data.headache.map(get)\n",
    "data.swollen_glands=data.swollen_glands.map(get)\n",
    "data.rashes=data.rashes.map(get)\n",
    "data.abdominal_pain=data.abdominal_pain.map(get)\n",
    "data.ble_nose=data.ble_nose.map(get)\n",
    "data.ble_mouth=data.ble_mouth.map(get)\n",
    "data.fatigue=data.fatigue.map(get)\n",
    "data.red_eyes=data.red_eyes.map(get)\n",
    "data.dengue=data.dengue.map(get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[:225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_n = data[data['dengue'] == 0]\n",
    "data_y = data[data['dengue'] == 1]\n",
    "\n",
    "c=0\n",
    "for i in data.dengue:\n",
    "    if i==1:\n",
    "        c=c+1\n",
    "score=c/data.shape[0]\n",
    "print('the bechmark model accuarcy score  {}%'.format(score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate figure object\n",
    "fig = plt.figure()\n",
    "#plt.sup_title('Tumor Characteristic (means)')\n",
    "\n",
    "# Create 'for loop' to enerate though tumor features and compare with histograms\n",
    "for i,b in enumerate(list(data.columns[0:16])):\n",
    "    \n",
    "    # Enumerate starts at index 0, need to add 1 for subplotting\n",
    "    i +=1\n",
    "    \n",
    "    # Create axes object for position i\n",
    "    ax = fig.add_subplot(4,4,i)\n",
    "    \n",
    "    # Plot via histogram tumor charateristics using stacked and alpha parameters for..\n",
    "    # comparisons.\n",
    "    ax.hist(data_n[b], label = 'Negative', stacked = True, alpha=0.5, color= 'g')\n",
    "    ax.hist(data_y[b], label= 'Positive', stacked = True, alpha=0.5, color= 'r')\n",
    "    ax.set_title(b)\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.legend()\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## heat map generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(data.corr(),annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to split the data into ratio of 75% and 25% to train model and test the model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "new_data=data.drop(columns={'dengue'})\n",
    "X_train,X_test,y_train,y_test=train_test_split(new_data,data['dengue'],random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data is preprocessing using sklearn.preprocessing.Normalizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "norm=Normalizer()\n",
    "X_train_normal=norm.transform(X_train)\n",
    "X_test_normal=norm.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "RF_params = {'n_estimators':[10,50,100]}\n",
    "DTC_params = {'criterion':['entropy'], 'max_depth':[10, 50, 100]}\n",
    "LR_params = {'C':[0.001, 0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "models=[]\n",
    "\n",
    "models.append(('DTC', DecisionTreeClassifier(), DTC_params))\n",
    "\n",
    "models.append(('LR', LogisticRegression(), LR_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "results=[]\n",
    "names=[]\n",
    "scoring='accuracy' \n",
    "for name, model, params in tqdm(models):\n",
    "    kfold = KFold(len(X_train_normal), random_state=7, shuffle=True)\n",
    "    model_grid = GridSearchCV(model, params)\n",
    "    cv_results = cross_val_score(model_grid, X_train_normal, y_train, cv = kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"Cross Validation Accuracy %s: Accarcy: %f SD: %f\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### White Grid Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(results, labels = names)\n",
    "plt.title('Dengue Diagnosis Performance using Machine Learning ')\n",
    "plt.ylabel('Model Accuracy %')\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The accuracy score obtained without using GridSearchCV\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, fbeta_score\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_normal,y_train)\n",
    "pred=clf.predict(X_test_normal)\n",
    "accuracy_score(pred,y_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data metric evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, fbeta_score\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# TODO: Create the parameters list you wish to tune\n",
    "parameters = {'criterion':['entropy'], 'max_depth':[10, 50, 100]}\n",
    "\n",
    "# TODO: Make an fbeta_score scoring object\n",
    "\n",
    "\n",
    "# TODO: Perform grid search on the classifier using 'scorer' as the scoring method\n",
    "grid_obj = GridSearchCV(clf,parameters,scoring='accuracy')\n",
    "\n",
    "# TODO: Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_fit = grid_obj.fit(X_train_normal,y_train)\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = grid_fit.best_estimator_\n",
    "\n",
    "# Make predictions using the unoptimized and model\n",
    "predictions = (clf.fit(X_train_normal, y_train)).predict(X_test_normal)\n",
    "best_predictions = best_clf.predict(X_test_normal)\n",
    "\n",
    "# Report the before-and-afterscores\n",
    "print(\"Unoptimized model\\n------\")\n",
    "print(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "print(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\n",
    "print(\"\\nOptimized Model\\n------\")\n",
    "print(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
    "print(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Confusion Matrix and Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "matrix=confusion_matrix(pred,y_test)\n",
    "matrix=pd.DataFrame(matrix,columns=['Predicted Negative','Predicted Postive'],index=['Actual Negative','Actual Positive'])\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(best_predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A=best_clf.predict([[102.5,0,0,0,1,0,0,1,1,0,1,0,0,0,1,0,290000]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.predict([[102.5,0,0,0,1,0,0,1,1,0,1,0,0,0,1,0,290000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.predict([[103.4,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,6000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.predict([[2.65640088e-03,2.56409351e-05,2.56409351e-05,0.00000000e+00,5.12818702e-05,0.00000000e+00,0.00000000e+00,0.00000000e+00,2.56409351e-05,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,2.56409351e-05,0.00000000e+00,9.99996469e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.predict([[6.73999847e-04,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,6.66666515e-06,6.66666515e-06,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,6.66666515e-06,0.00000000e+00,9.99999773e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.predict([[1.04094354e-02,0.00000000e+00,9.99945760e-05,9.99945760e-05,9.99945760e-05,0.00000000e+00,9.99945760e-05,9.99945760e-05,1.99989152e-04,0.00000000e+00,0.00000000e+00,9.99945760e-05,0.00000000e+00,9.99945760e-05,9.99945760e-05,0.00000000e+00,9.99945760e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.predict([[2.97645740e-03,2.94116344e-05,2.94116344e-05,2.94116344e-05,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,2.94116344e-05,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,2.94116344e-05,0.00000000e+00,9.99995568e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.predict([[4.50909045e-04,4.54545408e-06,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,4.54545408e-06,4.54545408e-06,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,9.99999898e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.predict([[4.56249952e-04,4.46428525e-06,4.46428525e-06,4.46428525e-06,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,4.46428525e-06,0.00000000e+00,4.46428525e-06,0.00000000e+00,0.00000000e+00,0.00000000e+00,4.46428525e-06,0.00000000e+00,9.99999896e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.predict([[9.92332036e-03,0.00000000e+00,9.52334008e-05,0.00000000e+00,1.90466802e-04,0.00000000e+00,1.90466802e-04,0.00000000e+00,0.00000000e+00,0.00000000e+00,9.52334008e-05,9.52334008e-05,0.00000000e+00,0.00000000e+00,0.00000000e+00,9.52334008e-05,9.99950708e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tval=norm.transform([[102.5,0,0,0,1,0,0,1,1,0,1,0,0,0,1,0,290000]])\n",
    "print(tval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = str(tval[[0]])\n",
    "element = element.strip('[').strip(']').split()\n",
    "print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf.predict([element])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tval=norm.transform([[103.5,1,1,1,2,1,1,1,1,1,0,1,1,0,1,0,6800]])\n",
    "print(tval)\n",
    "element = str(tval[[0]])\n",
    "element = element.strip('[').strip(']').split()\n",
    "print(element)\n",
    "best_clf.predict([element])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
