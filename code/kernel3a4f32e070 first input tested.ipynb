{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Dengue prediction and Analysis"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## read data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/dengue dataset.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## top 5 rows"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(columns={'id'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get={'yes':1,'medium':1,'no':0,'high':2,'low':0}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## data cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.vomiting=data.vomiting.map(get)\ndata.nausea=data.nausea.map(get)\ndata.vomiting_blood=data.vomiting_blood.map(get)\ndata.body_pains=data.body_pains.map(get)\ndata.pain_behind_eyes=data.pain_behind_eyes.map(get)\ndata.joint_pains=data.joint_pains.map(get)\ndata.chill=data.chill.map(get)\ndata.headache=data.headache.map(get)\ndata.swollen_glands=data.swollen_glands.map(get)\ndata.rashes=data.rashes.map(get)\ndata.abdominal_pain=data.abdominal_pain.map(get)\ndata.ble_nose=data.ble_nose.map(get)\ndata.ble_mouth=data.ble_mouth.map(get)\ndata.fatigue=data.fatigue.map(get)\ndata.red_eyes=data.red_eyes.map(get)\ndata.dengue=data.dengue.map(get)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data[:225]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata_n = data[data['dengue'] == 0]\ndata_y = data[data['dengue'] == 1]\n\nc=0\nfor i in data.dengue:\n    if i==1:\n        c=c+1\nscore=c/data.shape[0]\nprint('the bechmark model accuarcy score  {}%'.format(score*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## data visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Instantiate figure object\nfig = plt.figure()\n#plt.sup_title('Tumor Characteristic (means)')\n\n# Create 'for loop' to enerate though tumor features and compare with histograms\nfor i,b in enumerate(list(data.columns[0:16])):\n    \n    # Enumerate starts at index 0, need to add 1 for subplotting\n    i +=1\n    \n    # Create axes object for position i\n    ax = fig.add_subplot(4,4,i)\n    \n    # Plot via histogram tumor charateristics using stacked and alpha parameters for..\n    # comparisons.\n    ax.hist(data_n[b], label = 'Negative', stacked = True, alpha=0.5, color= 'g')\n    ax.hist(data_y[b], label= 'Positive', stacked = True, alpha=0.5, color= 'r')\n    ax.set_title(b)\n\n\n\nplt.tight_layout()\n#plt.legend()\nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## heat map generation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\nsns.heatmap(data.corr(),annot=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"## to split the data into ratio of 75% and 25% to train model and test the model\n\nfrom sklearn.model_selection import train_test_split\n\nnew_data=data.drop(columns={'dengue'})\nX_train,X_test,y_train,y_test=train_test_split(new_data,data['dengue'],random_state=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#The data is preprocessing using sklearn.preprocessing.Normalizer\nfrom sklearn.preprocessing import Normalizer\n\nnorm=Normalizer()\nX_train_normal=norm.transform(X_train)\nX_test_normal=norm.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_test_normal)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameter tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n\nRF_params = {'n_estimators':[10,50,100]}\nDTC_params = {'criterion':['entropy'], 'max_depth':[10, 50, 100]}\nLR_params = {'C':[0.001, 0.1, 1, 10, 100]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nmodels=[]\n\nmodels.append(('DTC', DecisionTreeClassifier(), DTC_params))\n\nmodels.append(('LR', LogisticRegression(), LR_params))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nresults=[]\nnames=[]\nscoring='accuracy' \nfor name, model, params in tqdm(models):\n    kfold = KFold(len(X_train_normal), random_state=7, shuffle=True)\n    model_grid = GridSearchCV(model, params)\n    cv_results = cross_val_score(model_grid, X_train_normal, y_train, cv = kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    msg = \"Cross Validation Accuracy %s: Accarcy: %f SD: %f\" % (name, cv_results.mean(), cv_results.std())\n    print(msg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### White Grid Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.boxplot(results, labels = names)\nplt.title('Dengue Diagnosis Performance using Machine Learning ')\nplt.ylabel('Model Accuracy %')\nsns.set_style(\"whitegrid\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"#The accuracy score obtained without using GridSearchCV\n\nfrom sklearn.metrics import make_scorer, accuracy_score, fbeta_score\n\nclf=RandomForestClassifier(n_estimators=100, random_state=42)\nclf.fit(X_train_normal,y_train)\npred=clf.predict(X_test_normal)\naccuracy_score(pred,y_test)\nprint(pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data metric evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import make_scorer, accuracy_score, fbeta_score\n\nclf = DecisionTreeClassifier(random_state=42)\n\n# TODO: Create the parameters list you wish to tune\nparameters = {'criterion':['entropy'], 'max_depth':[10, 50, 100]}\n\n# TODO: Make an fbeta_score scoring object\n\n\n# TODO: Perform grid search on the classifier using 'scorer' as the scoring method\ngrid_obj = GridSearchCV(clf,parameters,scoring='accuracy')\n\n# TODO: Fit the grid search object to the training data and find the optimal parameters\ngrid_fit = grid_obj.fit(X_train_normal,y_train)\n\n# Get the estimator\nbest_clf = grid_fit.best_estimator_\n\n# Make predictions using the unoptimized and model\npredictions = (clf.fit(X_train_normal, y_train)).predict(X_test_normal)\nbest_predictions = best_clf.predict(X_test_normal)\n\n# Report the before-and-afterscores\nprint(\"Unoptimized model\\n------\")\nprint(\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\nprint(\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions, beta = 0.5)))\nprint(\"\\nOptimized Model\\n------\")\nprint(\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\nprint(\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 0.5)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  Confusion Matrix and Classification report"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(best_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\n\nmatrix=confusion_matrix(pred,y_test)\nmatrix=pd.DataFrame(matrix,columns=['Predicted Negative','Predicted Postive'],index=['Actual Negative','Actual Positive'])\nprint(matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(best_predictions,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nA=best_clf.predict([[102.5,0,0,0,1,0,0,1,1,0,1,0,0,0,1,0,290000]])\nprint(A)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_clf.predict([[102.5,0,0,0,1,0,0,1,1,0,1,0,0,0,1,0,290000]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_clf.predict([[103.4,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,6000]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_clf.predict([[2.65640088e-03,2.56409351e-05,2.56409351e-05,0.00000000e+00,5.12818702e-05,0.00000000e+00,0.00000000e+00,0.00000000e+00,2.56409351e-05,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,2.56409351e-05,0.00000000e+00,9.99996469e-01]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_clf.predict([[6.73999847e-04,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,6.66666515e-06,6.66666515e-06,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,6.66666515e-06,0.00000000e+00,9.99999773e-01]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_clf.predict([[1.04094354e-02,0.00000000e+00,9.99945760e-05,9.99945760e-05,9.99945760e-05,0.00000000e+00,9.99945760e-05,9.99945760e-05,1.99989152e-04,0.00000000e+00,0.00000000e+00,9.99945760e-05,0.00000000e+00,9.99945760e-05,9.99945760e-05,0.00000000e+00,9.99945760e-01]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_clf.predict([[2.97645740e-03,2.94116344e-05,2.94116344e-05,2.94116344e-05,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,2.94116344e-05,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,2.94116344e-05,0.00000000e+00,9.99995568e-01]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_clf.predict([[4.50909045e-04,4.54545408e-06,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,4.54545408e-06,4.54545408e-06,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,9.99999898e-01]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_clf.predict([[4.56249952e-04,4.46428525e-06,4.46428525e-06,4.46428525e-06,0.00000000e+00,0.00000000e+00,0.00000000e+00,0.00000000e+00,4.46428525e-06,0.00000000e+00,4.46428525e-06,0.00000000e+00,0.00000000e+00,0.00000000e+00,4.46428525e-06,0.00000000e+00,9.99999896e-01]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_clf.predict([[9.92332036e-03,0.00000000e+00,9.52334008e-05,0.00000000e+00,1.90466802e-04,0.00000000e+00,1.90466802e-04,0.00000000e+00,0.00000000e+00,0.00000000e+00,9.52334008e-05,9.52334008e-05,0.00000000e+00,0.00000000e+00,0.00000000e+00,9.52334008e-05,9.99950708e-01]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tval=norm.transform([[102.5,0,0,0,1,0,0,1,1,0,1,0,0,0,1,0,290000]])\nprint(tval)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"element = str(tval[[0]])\nelement = element.strip('[').strip(']').split()\nprint(element)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(element)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_clf.predict([element])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tval=norm.transform([[103.5,1,1,1,2,1,1,1,1,1,0,1,1,0,1,0,6800]])\nprint(tval)\nelement = str(tval[[0]])\nelement = element.strip('[').strip(']').split()\nprint(element)\nbest_clf.predict([element])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}